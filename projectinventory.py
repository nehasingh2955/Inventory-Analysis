# -*- coding: utf-8 -*-
"""ProjectInventory.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14DL4BeZTjXA2DykwXKsegIxaGn3_ZTIT
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import seaborn as sns 
import matplotlib.pyplot as plt

 
# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list 
#  all files under the input directory

import os
inventoryData = pd.read_csv('../content/sample_data/SalesKaggle3.csv')

# As mentioned in our proposal, the dataset we are working with contains records
#  for 'Historical' and 'Active'.  Since we want to create a model based off 
# 'Historical' records, we will want to filter to those records only.

HistoricalData = inventoryData[inventoryData.File_Type=='Historical']

HistoricalData.head(20)

HistoricalData.apply(lambda x:sum(x.isnull()))

HistoricalData.describe()

# There are no records where there is null values.  For now, there is no need 
#  to impute

HistoricalData.info()

HistoricalData.apply(lambda x: len(x.unique()))

# Verify the number of unique MarketingType

n = len(pd.unique(HistoricalData['MarketingType']))
  
print("No.of.unique values :", n)

# Verify the number of unique SKU_Numbers i.e. products

n = len(pd.unique(HistoricalData['SKU_number']))
  
print("No.of.unique values :", n)

# Since our target data is the 'SoldFlag', we want to look at how many 
# products actually sold vs which products did not

sns.countplot(x="SoldFlag", data=HistoricalData)

UnitsSold_by_SoldFlag = pd.pivot_table(HistoricalData, index="SoldFlag", values="File_Type", aggfunc="count")

print(UnitsSold_by_SoldFlag)

"""## We see that the inventory has 63,000 unique products that have not sold in the past 6 months.

#### Graph above seems to indicate that the inventory has a lot of products that have not sold in the past 6 months.  Let's look at how much money has been spent to have those in stock.
"""

# We create a new column 'OverallCost' that multiplies the 'ItemCount' by 
#  'LowNetPrice'

HistoricalData['OverallCost'] = HistoricalData['ItemCount'] * HistoricalData['LowNetPrice']

HistoricalData.head()

# Aggregate 'OverallCost' by the 'SoldFlag'

CostbySoldFlag = HistoricalData.groupby('SoldFlag', as_index=False).agg({'OverallCost': 'sum'})

CostbySoldFlag

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

x = CostbySoldFlag['SoldFlag']
y = CostbySoldFlag['OverallCost']

x_pos = [i for i, _ in enumerate(x)]

plt.bar(x_pos, y)
plt.xlabel("Sold Flag")
plt.ylabel("Overall Cost")
plt.title('Overall Cost by Sold Flag')

plt.xticks(x_pos, x)

plt.show()

TotalCost_by_SoldFlag = HistoricalData.pivot_table(index="SoldFlag", values="OverallCost", aggfunc="sum")

print(TotalCost_by_SoldFlag)

"""## We see that it has cost the company 96,764,417 USD to have the unsold products in stock while it only cost 30,583,747 USD to stock products that have sold"""

# Let us format some of the columns into the correct format
# What we are doing here is converting the [MarketingType] column into a binary 
# format.  [MarketingType] has 2 distinct values "S" and "D", therefore we will
# have 1 column to represent whether a product is "S" (which is represented by 
# a 1 in column [S]) or if a product is "D" (represented with a 0 in [S])

new_HistData = HistoricalData
MarketingType_Binary = pd.get_dummies(new_HistData['MarketingType'], drop_first=True)


new_HistData = pd.concat([new_HistData, MarketingType_Binary], axis=1)

new_HistData.head(5)

# In this section, we will drop columns that are non-numeric or irrelevant to 
# to the model we will use.

new_HistData.drop(['Order', 'File_Type', 'SKU_number', 'SoldCount', 'MarketingType'], axis=1, inplace=True)

new_HistData.head(5)

"""# **Train Data**


"""

# We are now ready to train our dataset.  Our target variable will be [SoldFlag]
# , we will set that as our y.  All other variables are independent so we will
# place them in X.

y = new_HistData["SoldFlag"]
X = new_HistData.drop("SoldFlag", axis=1)

# Here we are splitting our testing and training data set for X and y

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

# The model we will use is LogisticRegression because we want to determine 
# whether we want to restock a product, binary in nature. The second line is 
# creating an instance of the LogisticRegression() method

from sklearn.linear_model import LogisticRegression

logmodel = LogisticRegression()

# In this section, we are fitting the data to the model.

logmodel.fit(X_train, y_train)

newPredictions = logmodel.predict(X_test)

newPredictions

from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, newPredictions)

# We now have our predictions, now we will use a Confusion Matrix to see how 
# well the model performed.  Confusion matrix contains information related to
# sensitivity and specificity i.e. what is a true positive and true negative.

import itertools

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()


# Compute confusion matrix
from sklearn.metrics import confusion_matrix

cnf_matrix = confusion_matrix(y_test, newPredictions)

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=['Positive','Negative'],
                      title='Confusion matrix, without normalization')

"""## From our confusion matrix, we can calculate our accuracy by adding True Positive (18,741) and True Negative (240) and dividing by total (18,741 + 182 + 3,636 + 240). This will give us an accuracy score of 0.83 """

# We can arrive at the same accuracy score by using the accuracy_score method

from sklearn.metrics import accuracy_score
accuracy_score(y_test, newPredictions)

# We will now use Decision Trees to have a different type of model to help
# with these decisions

from sklearn import tree

treeModel = tree.DecisionTreeClassifier()

# As we did in the logistic model, we are creating the model.

treeModel.fit(X_train, y_train)

# We track our predictions using the Decision Tree.  This will also be used in
# in a confusion matrix to score the accuracy of Decision Tree Model.

treepredictions = treeModel.predict(X_test)

# Compute confusion matrix
from sklearn.metrics import confusion_matrix

tree_cnf_matrix = confusion_matrix(y_test, treepredictions)

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(tree_cnf_matrix, classes=['Positive','Negative'],
                      title='Confusion matrix, without normalization')

"""## The confusion matrix for the Decision Tree is as follows, True Positive (15,877) and True Negative (1,161) and dividing by total (15,877 + 3,046 + 2,715 + 1,161). This will give us an accuracy score of 0.75

## **The accuracy score of the Decision Tree model is lower than the Logistic Model.  Because of that, we will go with the Logistic model for our problem.**
"""

from sklearn.metrics import accuracy_score
accuracy_score(y_test, treepredictions)

logmodel.predict_proba(X_test)

predictions = logmodel.predict_proba(X_test)[:,1]

predictions

# Once the model has been created and fitted with the dataset, we will make
# predictions using the model using the X_test dataset.  This will help 
# evaluate how well the model does.


# Create an empty list
filter_arr = []

# go through each element in arr
for element in predictions:
  # if the element is higher than 42, set the value to True, otherwise False:
  if element < 0.20:
    filter_arr.append(True)
  else:
    filter_arr.append(False)

newarr = predictions[filter_arr]

print(newarr)

